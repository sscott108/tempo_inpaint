{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "820ed3a6-0560-441c-8978-b67030403bd9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-51198b0e91ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_init\u001b[0m  \u001b[0;31m# pyright: ignore # noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m from pandas.core.api import (\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;31m# dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mArrowDtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m from pandas.core.groupby import (\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mGrouper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mNamedAgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/groupby/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.core.groupby.generic import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mDataFrameGroupBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mNamedAgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mSeriesGroupBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m )\n\u001b[1;32m     76\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m from pandas.core.groupby.groupby import (\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethods\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mselectn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmelt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmelt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseries\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_docs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_shared_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m from pandas.core.sorting import (\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;31m# error: Definition of \"min\" in base class \"IndexOpsMixin\" is incompatible with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;31m# definition in base class \"NDFrame\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexOpsMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \"\"\"\n\u001b[1;32m    246\u001b[0m     \u001b[0mOne\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0maxis\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mincluding\u001b[0m \u001b[0mtime\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mSeries\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5685\u001b[0m     \u001b[0;31m# error: Cannot determine type of 'asfreq'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5686\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[has-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5687\u001b[0;31m     def asfreq(\n\u001b[0m\u001b[1;32m   5688\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5689\u001b[0m         \u001b[0mfreq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFrequency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(decorated)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0mdocstring_components\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         params_applied = [\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         params_applied = [\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, glob, math, random\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from datetime import datetime\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from matplotlib.collections import LineCollection\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show as rio_show\n",
    "import re\n",
    "from rasterio.transform import array_bounds\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.cm as cm\n",
    "from tqdm import tqdm\n",
    "F32_MIN = np.float32(-3.4028235e+38).item()  # ~ -3.40282306e+38 in your files\n",
    "import pickle\n",
    "from matplotlib import patheffects as pe\n",
    "import shapefile\n",
    "from pyproj import CRS, Transformer\n",
    "import math, torch, torch.nn as nn, torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "import csv\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81621565-a8a8-4d3b-a0dc-cd9a20a8d28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader \n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.models import PConvUNet2D\n",
    "from src.data import TempoInpaintDataset, Normalizer, load_classification_pickle\n",
    "from src.losses import calculate_metrics, warmup_loss\n",
    "# save_classification_pickle(complete, partial, blank, output_file=\"file_classification_nop.pkl\")\n",
    "complete, partial, blank = load_classification_pickle()\n",
    "train_files, val_files = train_test_split(complete, test_size=0.2, random_state=42)\n",
    "tif_dir = '/work/srs108/bigs'\n",
    "\n",
    "z = np.load(\"/hpc/home/srs108/normalizer_stats.npz\", allow_pickle=True)\n",
    "normalizer = Normalizer(clip_z=5.0)\n",
    "\n",
    "normalizer.im_mu = float(z[\"im_mu\"]); normalizer.im_sigma = float(z[\"im_sigma\"])\n",
    "shp_path=\"/hpc/home/srs108/TEMPO/cus/cb_2018_us_state_500k.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "865a70f4-ba8c-4140-8c3d-66ec20fbbbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = TempoInpaintDataset(tif_dir=tif_dir,normalizer=normalizer, file_list=train_files ,train=True)\n",
    "# train_ds.sample_vis(300)\n",
    "# train_ds.sample_vis(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9974da37-e57a-4338-98e0-b7f757fcf46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TempoInpaintDataset(tif_dir=tif_dir,normalizer=normalizer, train=True, file_list=train_files)\n",
    "val_ds = TempoInpaintDataset(tif_dir=tif_dir, normalizer=normalizer,train=False,file_list=val_files)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=4, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90b5a64-efe1-4d29-9766-89364237f3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 188/1043 [01:20<06:13,  2.29it/s]"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=50, patience=5):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "    best_loss = float(\"inf\")\n",
    "    best_state = None\n",
    "    wait = 0\n",
    "\n",
    "    history = []\n",
    "    for epoch in range(epochs):\n",
    "        # ---- Training ----\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_metrics = {'rmse': 0.0, 'mae': 0.0, 'r2': 0.0}\n",
    "        batch_count = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader):\n",
    "            img = batch[\"img_w_both_masks\"].cuda()          # img with both masks\n",
    "            mask = batch[\"known_and_fake_mask\"].cuda()      # real missing gaps and artificial gaps\n",
    "            mask_aug = batch[\"fake_mask\"].cuda()            # 1=kept, 0=artificial hole\n",
    "            target = batch[\"target\"].cuda()\n",
    "\n",
    "            pred_t, pred_mask = model(img, mask_aug)\n",
    "            loss = warmup_loss(pred_t, target, mask)            \n",
    "            \n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Calculate metrics for fake mask regions\n",
    "            batch_metrics = calculate_metrics(pred_t, target, mask_aug)\n",
    "            for key in batch_metrics:\n",
    "                train_metrics[key] += batch_metrics[key]\n",
    "            batch_count += 1\n",
    "            \n",
    "\n",
    "        # Average metrics over batches\n",
    "        train_loss /= len(train_loader)\n",
    "        for key in train_metrics:\n",
    "            train_metrics[key] /= batch_count\n",
    "\n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_metrics = {'rmse': 0.0, 'mae': 0.0, 'r2': 0.0}\n",
    "        batch_count = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader):\n",
    "                img = batch[\"img_w_both_masks\"].cuda()\n",
    "                mask = batch[\"known_and_fake_mask\"].cuda()\n",
    "                mask_aug = batch[\"fake_mask\"].cuda()  # Add this line to get fake mask\n",
    "                target = batch[\"target\"].cuda()\n",
    "                pred, pred_mask = model(img, mask)\n",
    "\n",
    "                loss = warmup_loss(pred, target, mask)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # Calculate metrics for fake mask regions\n",
    "                batch_metrics = calculate_metrics(pred, target, mask_aug)\n",
    "                for key in batch_metrics:\n",
    "                    val_metrics[key] += batch_metrics[key]\n",
    "                batch_count += 1\n",
    "                \n",
    "        val_loss /= len(val_loader)\n",
    "        for key in val_metrics:\n",
    "            val_metrics[key] /= batch_count\n",
    "    \n",
    "        print(f\"Epoch {epoch+1}: Train {train_loss:.4f} | Val {val_loss:.4f}\")\n",
    "        print(f\"Train metrics - RMSE: {train_metrics['rmse']:.4f}, MAE: {train_metrics['mae']:.4f}, R²: {train_metrics['r2']:.4f}\")\n",
    "        print(f\"Val metrics - RMSE: {val_metrics['rmse']:.4f}, MAE: {val_metrics['mae']:.4f}, R²: {val_metrics['r2']:.4f}\")\n",
    "        \n",
    "                    \n",
    "        visualize_batch(epoch, model, train_ds, idx=300, device=\"cuda\",train=True, save=True)\n",
    "        visualize_batch(epoch, model, val_ds, idx=19, device=\"cuda\", train=False, save = True)\n",
    "        \n",
    "        # ---- Early stopping ----\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_state = model.state_dict().copy()\n",
    "            wait = 0\n",
    "            torch.save(model.state_dict(), \"pconvunet.pt\")\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "                \n",
    "        history.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"train_rmse\": train_metrics['rmse'],\n",
    "            \"train_mae\": train_metrics['mae'],\n",
    "            \"train_r2\": train_metrics['r2'],\n",
    "            \"val_rmse\": val_metrics['rmse'],\n",
    "            \"val_mae\": val_metrics['mae'],\n",
    "            \"val_r2\": val_metrics['r2'],\n",
    "            \"pred_min_range\": pred.min().item() if 'pred' in locals() else None,\n",
    "            \"pred_max_range\": pred.max().item() if 'pred' in locals() else None\n",
    "        })\n",
    "        \n",
    "        with open('csv_history.csv', \"w\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=[\n",
    "                \"epoch\", \"train_loss\", \"val_loss\", \n",
    "                \"train_rmse\", \"train_mae\", \"train_r2\",\n",
    "                \"val_rmse\", \"val_mae\", \"val_r2\",\n",
    "                \"pred_min_range\", \"pred_max_range\"\n",
    "            ])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(history)\n",
    "        \n",
    "    # Restore best weights\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "model = PConvUNet2D(in_ch=1, out_ch=1, base_ch=32).cuda()\n",
    "model = train_model(model, train_loader, val_loader, epochs=150, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a328ced-45b6-450a-8a6f-a9f922557e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
